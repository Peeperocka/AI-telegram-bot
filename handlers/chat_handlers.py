import io
import os
import tempfile
import aiogram.exceptions

from PIL import Image
from aiogram import Router, types, F
from aiogram.enums import ParseMode
from aiogram.fsm.context import FSMContext
from io import BytesIO
from states import ChatState
from keyboards.reply_keyboards import get_settings_reply_keyboard
from aiogram.types import BufferedInputFile
from registry import AIRegistry, TextToTextModel, TextToImgModel, ImgToTextModel, AudioToTextModel
from utils.utils import split_text

router = Router()


async def _handle_model_response(message: types.Message, response):
    if isinstance(response, BytesIO):
        try:
            response.seek(0)
            with Image.open(response) as img:
                bio = io.BytesIO()
                img.save(bio, 'PNG')
                bio.seek(0)
                await message.answer_photo(
                    BufferedInputFile(bio.read(), filename="image.png"),
                    reply_markup=get_settings_reply_keyboard()
                )
        except Exception as e:
            print(e)
            await message.answer(
                f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.",
                reply_markup=get_settings_reply_keyboard()
            )
    elif isinstance(response, str):
        message_parts = split_text(response)
        for i, part in enumerate(message_parts):
            reply_markup = get_settings_reply_keyboard() if i == 0 else None
            try:
                await message.answer(
                    text=part,
                    reply_markup=reply_markup,
                    parse_mode=ParseMode.MARKDOWN,
                    disable_web_page_preview=True
                )
            except aiogram.exceptions.TelegramAPIError as e:
                print(e)
                error_msg = f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏—è"
                try:
                    await message.answer(
                        text=part.replace("*", ""),
                        reply_markup=reply_markup
                    )
                except aiogram.exceptions.TelegramAPIError as e:
                    print(e)
                    if i == 0:
                        await message.answer(error_msg, reply_markup=get_settings_reply_keyboard())
                    else:
                        await message.answer(error_msg)
                    break

    elif response is None:
        await message.answer(
            "üö´ –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç –º–æ–¥–µ–ª–∏",
            reply_markup=get_settings_reply_keyboard()
        )

    else:
        print(type(response))
        print(response)
        await message.answer(
            "‚ö†Ô∏è –ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞",
            reply_markup=get_settings_reply_keyboard()
        )


@router.message(ChatState.waiting_query, F.voice)
async def voice_query_handler(message: types.Message, state: FSMContext) -> None:
    await message.answer("‚è≥")
    user_data = await state.get_data()
    model_id = user_data.get("model_id", "default")
    registry = AIRegistry()

    try:
        voice = message.voice
        voice_bytes = await message.bot.download(voice)

        with tempfile.TemporaryDirectory() as temp_dir:
            audio_path = os.path.join(temp_dir, "audio.ogg")

            with open(audio_path, "wb") as f:
                f.write(voice_bytes.read())

            provider, version = model_id.split(":") if ":" in model_id else (None, None)
            model = registry.get_model(provider, version) if provider else None

            if model and AudioToTextModel in model.meta.capabilities:
                response = await model.execute(voice_bytes)
                return await _handle_model_response(message, response)

            whisper_model = registry.get_model("whisper", "whisper-large-v3")
            if not whisper_model:
                await message.answer("‚ö†Ô∏è –û—à–∏–±–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏: –º–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
                return

            transcription = await whisper_model.execute(audio_path)

            if not model:
                await message.answer(f"‚ùìÔ∏è –ú–æ–¥–µ–ª—å {model_id} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
                return

            if TextToTextModel in model.meta.capabilities:
                response = await model.execute(transcription)
            elif TextToImgModel in model.meta.capabilities:
                response = await model.execute(transcription)
            else:
                response = f"üö´ –ú–æ–¥–µ–ª—å {model_id} –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –≥–æ–ª–æ—Å–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã"

            await _handle_model_response(message, response)

    except Exception as e:
        print(e)
        await message.answer(
            "üö´ –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç –º–æ–¥–µ–ª–∏",
            reply_markup=get_settings_reply_keyboard(),
            parse_mode="Markdown"
        )


@router.message(ChatState.waiting_query, F.photo)
async def photo_query_handler(message: types.Message, state: FSMContext) -> None:
    await message.answer("‚è≥")
    user_data = await state.get_data()
    model_id = user_data.get("model_id", "default")
    registry = AIRegistry()

    try:
        photo = message.photo[-1]
        photo_bytes = await message.bot.download(photo)
        image_data = BytesIO(photo_bytes.read())
        prompt = message.caption or ""

        if model_id == "default":
            await message.answer("–†–µ–∂–∏–º –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è")
            return

        provider, version = model_id.split(":")
        model = registry.get_model(provider, version)

        if not model:
            await message.answer(f"‚ùìÔ∏è –ú–æ–¥–µ–ª—å {model_id} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
            return

        if ImgToTextModel in model.meta.capabilities:
            response = await model.execute(image_data, prompt)
        else:
            response = f"üö´ –ú–æ–¥–µ–ª—å {model_id} –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∫—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π"

        await _handle_model_response(message, response)

    except Exception as e:
        print(e)
        await message.answer(f"‚ö†Ô∏è –û—à–∏–±–∫–∞, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑ –ø–æ–∑–∂–µ",
                             reply_markup=get_settings_reply_keyboard(), parse_mode="Markdown")


@router.message(ChatState.waiting_query, F.text)
async def text_query_handler(message: types.Message, state: FSMContext) -> None:
    await message.answer("‚è≥")
    user_data = await state.get_data()
    model_id = user_data.get("model_id", "default")
    registry = AIRegistry()

    try:
        if model_id == "default":
            await message.answer("–†–µ–∂–∏–º –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –Ω–µ –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω")
            return

        provider, version = model_id.split(":")
        model = registry.get_model(provider, version)

        if not model:
            await message.answer(f"–ú–æ–¥–µ–ª—å {model_id} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
            return

        if TextToTextModel in model.meta.capabilities or TextToImgModel in model.meta.capabilities:
            response = await model.execute(message.text)
            await _handle_model_response(message, response)
        else:
            await message.answer(
                f"üö´ –ú–æ–¥–µ–ª—å {model_id} –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã",
                reply_markup=get_settings_reply_keyboard()
            )

    except ValueError as e:
        print(e)
        await message.answer("üö´ –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç –º–æ–¥–µ–ª–∏", reply_markup=get_settings_reply_keyboard(),
                             parse_mode="Markdown")


@router.message(ChatState.waiting_query, F.content_types.ANY)
async def unknown_message_in_chat_handler(message: types.Message) -> None:
    await message.answer("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–ø—Ä–∞–≤—å—Ç–µ —Ç–µ–∫—Å—Ç, –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–ª–∏ –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏.")
